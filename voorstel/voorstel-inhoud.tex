%---------- Inleiding ---------------------------------------------------------
\section{Inleiding}%
\label{sec:inleiding}
%Waarover zal je bachelorproef gaan? Introduceer het thema en zorg dat volgende zaken zeker duidelijk aanwezig zijn:

%\begin{itemize}
%  \item kaderen thema
%  \item de doelgroep
%  \item de probleemstelling en (centrale) onderzoeksvraag
%  \item de onderzoeksdoelstelling
%\end{itemize}

%Denk er aan: een typische bachelorproef is \textit{toegepast onderzoek}, wat betekent dat je start vanuit een concrete probleemsituatie in bedrijfscontext, een \textbf{casus}. Het is belangrijk om je onderwerp goed af te bakenen: je gaat voor die \textit{ene specifieke probleemsituatie} op zoek naar een goede oplossing, op basis van de huidige kennis in het vakgebied.

%De doelgroep moet ook concreet en duidelijk zijn, dus geen algemene of vaag gedefinieerde groepen zoals \emph{bedrijven}, \emph{developers}, \emph{Vlamingen}, enz. Je richt je in elk geval op it-professionals, een bachelorproef is geen populariserende tekst. Eén specifiek bedrijf (die te maken hebben met een concrete probleemsituatie) is dus beter dan \emph{bedrijven} in het algemeen.

%Formuleer duidelijk de onderzoeksvraag! De begeleiders lezen nog steeds te veel voorstellen waarin we geen onderzoeksvraag terugvinden.

%Schrijf ook iets over de doelstelling. Wat zie je als het concrete eindresultaat van je onderzoek, naast de uitgeschreven scriptie? Is het een proof-of-concept, een rapport met aanbevelingen, \ldots Met welk eindresultaat kan je je bachelorproef als een succes beschouwen?

Iedereen heeft het wel al eens meegemaakt: je zoekt online naar een supermarkt in de buurt, je vertrekt op basis van deze gegevens, 
maar eenmaal aangekomen blijkt dat de winkel gesloten of zelfs verdwenen is. 
Voor consumenten is dit vervelend, maar voor bedrijven die hun beslissingen baseren op deze locatiegegevens kan het drastische gevolgen 
hebben. Deze bachelorproef onderzoekt hoe we met artificiële intelligentie dit probleem kunnen aanpakken.

Organisaties die werken met locatie data maken gebruik van POI (Point-of-interest) gegevens om analyses te maken rond bezoekersgedrag, 
marktpotentieel en concurrentie. Daarbij is het cruciaal dat de gegevens kwalitatief en up-to-date zijn. In de praktijk blijkt echter dat 
POI databanken vertraging oplopen: winkels openen of sluiten zonder dat dit meteen wordt weergegeven. Dat leidt tot foutieve inzichten en 
beïnvloedt de betrouwbaarheid van locatiegebaseerde toepassingen.

Huidige methoden om deze statuswijzigingen te monitoren zijn vaak handmatig, wat resulteert in 
een aanzienlijke vertraging tussen de daadwerkelijke status van de POI en de databanken.

De centrale onderzoeksvraag van deze bachelorproef is: \textit{“Hoe kan artificiële intelligentie worden ingezet om automatisch de 
(historische) open- of geslotenstatus van Points-of-Interest te detecteren, en hoe kan deze aanpak zorgen voor actuelere data in 
locatiegebaseerde toepassingen?”}.

Het onderzoek focust zich op supermarkten als POI type. Dit omwille van hun relevantie, hun duidelijk statusgedrag (open of gesloten) en 
de beschikbaarheid van voldoende publieke data via platformen zoals Google Maps of Tripadvisor. 

Om deze centrale onderzoeksvraag te beantwoorden worden onderstaande deelvragen onderzocht.
Deze hebben enerzijds betrekking tot het probleemdomein, anderzijds tot het oplossingsdomein.

\textbf{Deelvragen probleemdomein:}
\begin{itemize}
  \item Welke gegevensbronnen kunnen worden gebruikt voor het automatisch bepalen of een POI (historisch) open of gesloten is?
  \item Wat zijn de uitdagingen bij het implementeren van AI voor POI status detectie?
\end{itemize}


\textbf{Deelvragen oplossingsdomein:}
\begin{itemize}
    \item Welke AI- en machine learning technieken zijn geschikt voor de detectie van historische POI openingen en sluitingen, en wat zijn de voor en nadelen?
    \item Hoe kan de betrouwbaarheid van automatisch gedetecteerde wijzigingen in de bedrijfstoestand van POI’s worden gevalideerd?
\end{itemize}

Het doel van deze bachelorproef is het ontwikkelen van een proof-of-concept waarmee voorspeld kan worden of een supermarkt op een 
bepaald moment open of gesloten is. Hiervoor worden verschillende AI-technieken onderzocht en toegepast, waaronder tijdreeksanalyse en 
anomaliedetectie. De verschillende modellen worden geëvalueerd en met elkaar vergeleken op basis van prestatiecriteria zoals accuracy, 
recall en precisie. Het eindresultaat is een werkend prototype, aangevuld met een evaluatie van de modellen en aanbevelingen voor verdere 
onderzoek. De doelgroep van dit onderzoek bestaat uit organisaties die werken met POI data.

%---------- Stand van zaken ---------------------------------------------------
\section{Literatuurstudie}%
\label{sec:literatuurstudie}

%Hier beschrijf je de \emph{state-of-the-art} rondom je gekozen onderzoeksdomein, d.w.z.\ een inleidende, doorlopende tekst over het onderzoeksdomein van je bachelorproef. Je steunt daarbij heel sterk op de professionele \emph{vakliteratuur}, en niet zozeer op populariserende teksten voor een breed publiek. Wat is de huidige stand van zaken in dit domein, en wat zijn nog eventuele open vragen (die misschien de aanleiding waren tot je onderzoeksvraag!)?

%Je mag de titel van deze sectie ook aanpassen (literatuurstudie, stand van zaken, enz.). Zijn er al gelijkaardige onderzoeken gevoerd? Wat concluderen ze? Wat is het verschil met jouw onderzoek?

%Verwijs bij elke introductie van een term of bewering over het domein naar de vakliteratuur, bijvoorbeeld~\autocite{Hykes2013}! Denk zeker goed na welke werken je refereert en waarom.

%Draag zorg voor correcte literatuurverwijzingen! Een bronvermelding hoort thuis \emph{binnen} de zin waar je je op die bron baseert, dus niet er buiten! Maak meteen een verwijzing als je gebruik maakt van een bron. Doe dit dus \emph{niet} aan het einde van een lange paragraaf. Baseer nooit teveel aansluitende tekst op eenzelfde bron.

%Als je informatie over bronnen verzamelt in JabRef, zorg er dan voor dat alle nodige info aanwezig is om de bron terug te vinden (zoals uitvoerig besproken in de lessen Research Methods).

% Voor literatuurverwijzingen zijn er twee belangrijke commando's:
% \autocite{KEY} => (Auteur, jaartal) Gebruik dit als de naam van de auteur
%   geen onderdeel is van de zin.
% \textcite{KEY} => Auteur (jaartal)  Gebruik dit als de auteursnaam wel een
%   functie heeft in de zin (bv. ``Uit onderzoek door Doll & Hill (1954) bleek
%   ...'')

%Je mag deze sectie nog verder onderverdelen in subsecties als dit de structuur van de tekst kan verduidelijken.

De literatuurstudie biedt een overzicht van de huidige stand van zaken rond de POI-statusdetectie. Het dient als basis voor de methodologieën en is 
opgebouwd rond de deelvragen die het onderzoek sturen. Elke subsectie geeft een samenvatting van relevante vakliteratuur en legt de link met de gewenste 
toepassing van het automatisch bepalen of een Point-of-Interest (zoals een supermarkt) open of gesloten is .

\subsection{Welke gegevensbronnen kunnen worden gebruikt voor het automatisch bepalen of een POI (historisch) open of gesloten is?}

Het verzamelen van POI data is een complex proces en tevens ook de primaire oorzaak van de veroudering van locatiegegevens, waardoor het garanderen van de actualiteit van deze data een cruciale uitdaging vormt.

\textcite{Anishma2025} bespreekt diverse methoden die gebruikt worden voor de initiële verzameling van POI gegevens. Zo worden geautomatiseerde methoden zoals Web Scraping gebruikt om grote hoeveelheden gegevens van openbare websites of online gidsen te verzamelen, maar de betrouwbaarheid van deze data is meestal relatief laag. API's stellen software in staat om gegevens rechtstreeks van vertrouwde databanken op te halen. Daarnaast wordt de data aangevuld via Bedrijfsvermeldingen (officiële inzendingen over een bedrijf) en Crowdsourcing (door de gemeenschap gedreven input). Hoewel deze laatste twee methoden realtime informatie kunnen opleveren, vereisen ze strenge moderatie om de nauwkeurigheid te waarborgen. Ten slotte is er Field Collection, dit is een tijdrovende veldmethode waarbij teams het veld worden ingestuurd om locaties handmatig te bevestigen.

Volgens \textcite{Psyllidis2022} onderscheiden we twee hoofdtypen POI bronnen: enerzijds grote technologiebedrijven (waaronder Yelp, Foursquare, Google Places en Facebook) vormen een belangrijke bron van POI-gegevens, waarbij hun intern gecreëerde databanken vaak via API’s worden aangeboden \autocite{Psyllidis2022}. Anderzijds worden open platforms zoals OpenStreetMap (OSM) als gratis en wereldwijd toegankelijke POI-bron gebruikt. Hierbij dient opgemerkt te worden dat een aanzienlijk deel van de data van OSM afkomstig is van bedrijfsmatige bijdragen \autocite{Anderson2019}.

 In de studie van \textcite{Yao2024} wordt een dataset van geanonimiseerde AMAP mobiliteitsdata gebruikt om de dagelijkse activiteit bij POI’s te meten. Het onderzoek stelt dat een plotselinge daling in voetgangers- of transactionele activiteiten een sluiting aanduidt, omdat deze activiteit normaal gesproken continu is zolang de winkels geopend zijn. In essentie duidt een POI-anomalie dus op een significante afname of verdwijning van de bijbehorende menselijke activiteiten. Ook \textcite{Taylor2022} adviseert het controleren van voetverkeer en transactiegegevens als belangrijke indicator voor de status van een locatie.

Tot slot zijn er Beeld- en sensorbronnen, zoals google street view. Volgens \textcite{Pericolosi2022} gebruikt Google Maps bijvoorbeeld street View beelden en tekstherkenning om na te gaan of op gevels nieuwe bedrijfsnamen of borden verschijnen of deze juist verdwijnen. \textcite{Revaud2019} vergelijken twee sets google street view foto’s van hetzelfde winkelcentrum op verschillende tijdstippen om POI wijzigingen te detecteren met behulp van deep learning. 

\subsection{Wat zijn de uitdagingen bij het implementeren van AI voor POI status detectie?}
Het toepassen van AI voor POI statusdetectie kent verschillende uitdagingen.  

Ten eerste hebben we de data kwaliteit en actualiteit. Het waarborgen van de kwaliteit van POI-gegevens is een andere belangrijke uitdaging. Omdat gegevens uit meerdere bronnen worden verzameld, kunnen ze vaak gefragmenteerd, inconsistent en verouderd zijn \autocite{Rafaqat2023}. Deze uitdaging wordt versterkt door de dynamiek van de fysieke wereld. \textcite{Fernandes2020} benadrukt dat er nog openstaande uitdagingen zijn met betrekking tot de temporele en historische aspecten van deze data. Veel commerciële POI-data wordt bovendien slechts periodiek (bijvoorbeeld elke drie tot zes maanden) bijgewerkt, wat een aanzienlijke validatieachterstand creëert. Zonder tijdige validatie neemt de betrouwbaarheid van de data snel af.

Ten tweede hebben we ruis en algoritmische dubbelzinnigheid. AI-modellen moeten in staat zijn om een daadwerkelijke statusverandering te onderscheiden van tijdelijke variaties of omgevingsruis in visuele data. Ruisbronnen zoals schaduwen, wisselende lichtomstandigheden, occlusies, of seizoensgebonden winkelindelingen kunnen ten onrechte worden gedetecteerd als permanente verandering \autocite{Revaud2019}. Deze uitdaging leidt tot algoritmische dubbelzinnigheid: volgens \textcite{Revaud2019} zijn algoritmen die enkel op pixelniveau verandering detecteren blind voor de semantiek.

Tot slot hebben we model drift en geospatial bias. Zodra AI-modellen in productie zijn, ondergaan ze onvermijdelijk prestatievermindering dat model drift ofwel data drift wordt genoemd. Deze termen wordt gebruikt als een overkoepelende term die zowel conceptuele- als datadrift omvat en duidt op elke verslechtering van de modelprestaties als gevolg van veranderende datapatronen \autocite{Iyer2025}. Daarnaast kan Geospatial Bias (vooroordelen in de geografische distributie van de trainingsdata) leiden tot ongelijke prestaties, waarbij de nauwkeurigheid van het model lager is in minder bezochte gebieden en gebieden met weinig data \autocite{Raza2025}.

\subsection{Welke AI- en machine learning technieken zijn geschikt voor de detectie van historische POI openingen en sluitingen, en wat zijn de voor en nadelen?}

De statusdetectie wordt in de academische wereld vaak behandeld als een Time-to-Event prediction probleem (Survival Analysis), waarbij het model de resterende levensduur van de POI probeert te voorspellen \autocite{Chen2024}. Dit vereist geavanceerde Deep Learning architecturen die geschikt zijn voor het analyseren van de data. De literatuur richt zich hierbij op drie mogelijke technieken:

Een traditionele aanpak om POI openingen en sluitingen te voorspellen is via een classificatiemodel op basis van diverse datakenmerken. Zo ontwikkelden \textcite{DSilva2018} een model dat met locatie en mobiliteitsdata berekent hoe waarschijnlijk het is dat een bedrijf binnen een bepaalde periode (bv. 6 maanden) sluit. Ze combineerden kenmerken van de omgeving (diversiteit en concurrentie), bezoekpatronen en mobiliteitsstromen in een machine learning model. 

\textcite{DSilva2018} bespreken het voordeel en nadeel:
\begin{itemize}
    \item Voordeel: Deze methode is interpreteerbaar en laat toe inzicht te krijgen in welke factoren het meest bijdragen aan het sluitingsrisico. Klassieke classifiers (zoals logistieke regressie of random forest) vereisen minder data dan deep learning en kunnen met beperkte gelabelde data worden getraind.
    \item Nadeel: Een supervised model vergt voldoende historische data van POI openingen/sluitingen. Daarnaast werkt deze benadering op een vooraf gedefinieerde tijdsresolutie (bijv. voorspellen of een POI binnen 6 maanden zal sluiten) het is niet eenvoudig om het exacte moment van sluiting te identificeren omdat de data vaak te veel ruis heeft. Hierdoor kan het model kortetermijnveranderingen missen. 
\end{itemize}

Een veelgebruikte benadering is time series analysis (TSA) op voetverkeer- of transactiegegevens. \textcite{Yao2024} hebben een temporeel statusregressienetwerk (TSRNet) model ontwikkeld voor snelle POI-afwijkingsdetectie. Het model kan temporele kenmerken in data over menselijke activiteit extraheren en POI-statusscores voorspellen als afwijkingsindicatoren. Daarnaast wordt in het onderzoek ook besproken dat externe factoren, zoals weersomstandigheden en feestdagen, invloed hebben op het patroon van menselijke activiteit bij een POI. 

\textcite{Yao2024} bespreekt het voordeel en nadeel:
\begin{itemize}
  \item Voordeel: De benadering kan zeer adaptief zijn en sluitingen van POIs soms weken voor de eerste formele meldingen detecteren. Dit kan vooral wanneer check-in data van de POI en naburige locaties worden gebruikt.
  \item Nadeel: Omdat het vrijwel onmogelijk is om het exacte tijdstip van een anomalie te bepalen, genereren we onnauwkeurige POI-statussequenties als zwakke labels. Het TSRNet model vereist veel trainingsdata en is gevoelig voor ruis, zoals door tijdelijke dalingen in activiteit die geen permanente sluiting betekenen. Daarnaast is het gemakkelijk om POIs met schaarse gegevens over menselijke activiteit als afwijkingen te herkennen. Tot slot is het model minder geschikt wanneer de data geen duidelijke seizoenspatronen vertoond.
\end{itemize}

Een andere methode is Computervision (CV) op basis van Remote Sensing of straatbeelden om veranderingen te detecteren. \textcite{Revaud2019} hebben een Deep Learning framework ontwikkeld dat is geïnspireerd op basis van metric learning. Dit traint een embedding ruimte waarin afbeeldingen van dezelfde locatie (zonder verandering) dicht bij elkaar liggen, en gewijzigde locaties (bijvoorbeeld een verdwenen bord) afwijkend zijn. Door gebruik te maken van Siamese netwerken kunnen de evolutionaire context en sequentiële beelden over tijd worden verwerkt.

\textcite{Revaud2019} bespreken het voordeel en nadeel: 
\begin{itemize}   
    \item Voordeel: Het model is niet afhankelijk van externe bedrijfsdatabases voor de primaire detectie van de verandering.   
    \item Nadeel: De vergelijking is zeer complex en moet robuust zijn tegen ruis zoals wisselende belichting, schaduwen, occlusies en grote verschillen in camerastandpunt en schaling. 
\end{itemize}

\subsection{Hoe kan de betrouwbaarheid van automatisch gedetecteerde wijzigingen in de bedrijfstoestand van POI’s worden gevalideerd?}
Om de betrouwbaarheid van geautomatiseerde POI-statuswijzigingen te valideren, wordt in de literatuur nadruk gelegd op het combineren van meerdere bronnen en methoden. \textcite{Taylor2022} adviseert bijvoorbeeld om een voorspelde sluiting of opening te controleren met ondersteunende data: als de AI signalen van sluiting geeft, dan zou men in de voetgangers of transactiegegevens daadwerkelijk een significante afwezigheid moeten zien. Ook kunnen sateliet of lucht foto’s gecontroleerd worden op veranderingen (zoals een verbouwing) die de sluiting bevestigen \autocite{Taylor2022}.

Google maakt intensief gebruik van haar community (Local Guides, bedrijfsbeheerders en lokale overheden) om actuele POI-informatie te krijgen. Als algoritmisch een sluiting is gedetecteerd, kan men nagaan of bedrijfsbeheerders of lokale gidsen al een melding van sluiting hebben geplaatst \autocite{Pericolosi2022}.

Tot slot kan men gebruik maken van een “ground truth” dataset van bekende opening- en sluitingstijden (zoals bijvoorbeeld POI’s waarvan de sluiting publiek bekend is) en daarop de precision of recall van de automatische detectie meten. \textcite{Yao2024} kon bijvoorbeeld aantonen dat hun model POI-afwijkingen gemiddeld 15,7 dagen voor de gebruikersmelding signaleert, wat aangeeft dat het systeem grotendeels betrouwbaar vroegtijdig identificeert.

%---------- Methodologie ------------------------------------------------------
\section{Methodologie}%
\label{sec:methodologie}

%Hier beschrijf je hoe je van plan bent het onderzoek te voeren. Welke onderzoekstechniek ga je toepassen om elk van je onderzoeksvragen te beantwoorden? Gebruik je hiervoor literatuurstudie, interviews met belanghebbenden (bv.~voor requirements-analyse), experimenten, simulaties, vergelijkende studie, risico-analyse, PoC, \ldots?

%Valt je onderwerp onder één van de typische soorten bachelorproeven die besproken zijn in de lessen Research Methods (bv.\ vergelijkende studie of risico-analyse)? Zorg er dan ook voor dat we duidelijk de verschillende stappen terug vinden die we verwachten in dit soort onderzoek!

%Vermijd onderzoekstechnieken die geen objectieve, meetbare resultaten kunnen opleveren. Enquêtes, bijvoorbeeld, zijn voor een bachelorproef informatica meestal \textbf{niet geschikt}. De antwoorden zijn eerder meningen dan feiten en in de praktijk blijkt het ook bijzonder moeilijk om voldoende respondenten te vinden. Studenten die een enquête willen voeren, hebben meestal ook geen goede definitie van de populatie, waardoor ook niet kan aangetoond worden dat eventuele resultaten representatief zijn.

%Uit dit onderdeel moet duidelijk naar voor komen dat je bachelorproef ook technisch voldoen\-de diepgang zal bevatten. Het zou niet kloppen als een bachelorproef informatica ook door bv.\ een student marketing zou kunnen uitgevoerd worden.

%Je beschrijft ook al welke tools (hardware, software, diensten, \ldots) je denkt hiervoor te gebruiken of te ontwikkelen.

%Probeer ook een tijdschatting te maken. Hoe lang zal je met elke fase van je onderzoek bezig zijn en wat zijn de concrete \emph{deliverables} in elke fase?

Deze bachelorproef zal uitgewerkt worden in verschillende fasen. In elk van deze fasen wordt een andere techniek gebruikt, en wordt de focus op een ander onderdeel van het probleem gelegd. In totaal zijn er 14 werkdagen voorzien voor de bachelorproef. Aangezien er één werkdag per week besteed wordt aan het onderzoek, komt één werkdag overeen met 1 week. Een overzicht van de fasen wordt weergegeven in Figuur ~\ref{fig:gantt}.

\subsection{Fase 1 – Probleemdomein onderzoeken (1 werkdag)}
In de eerste fase van het onderzoek, wordt het concrete probleemdomein verder afgebakend. Er wordt een analyse gemaakt van hoe Point-of-Interest gegevens worden gebruikt door datagedreven organisaties, aangezien dit de primaire doelgroep van deze bachelorproef is. Daarnaast wordt onderzocht wat de impact is van verouderde of foutieve Point-of-Interest informatie op de kwaliteit van analyses. Het resultaat van deze fase is een duidelijker inzicht krijgen in het probleemdomein, dat kan gebruikt worden in de volgende fase.

\subsection{Fase 2 – Literatuurstudie (2 werkdagen)}
De tweede fase wordt toegewijd aan de literatuurstudie. Deze wordt uitgevoerd om informatie te vergaren over bestaande technieken en modellen die worden gebruikt voor de detectie van (historische) open of gesloten toestanden van Points-of-Interests (POI's). Hierbij wordt de nadruk gelegd op AI toepassingen zoals tijdreeksanalyses en anomalie detectie. De focus ligt op het identificeren van academische en wetenschappelijke publicaties waarin POI open/gesloten statusdetectie wordt behandeld aan de hand van machine learning of datagestuurde methodes.
Het resultaat van deze fase is een onderbouwde lijst van bruikbare technieken en modellen, inclusief technische eigenschappen en eventuele beperkingen. Deze vormen de basis voor de modelkeuze in de volgende fases van het onderzoek.

\subsection{Fase 3 – Data verzamelen en voorbereiden (3 werkdagen)}
Tijdens de derde fase zal de data verzameld en voorbereid worden. Een deel van de data zal rechtstreeks ter beschikking gesteld worden door de stageplaats (Accurat). Deze bevat vermoedelijk POI informatie zoals locatiegegevens, tijdreeksen van bezoekersactiviteit en labels met open of gesloten status. Daarnaast wordt de aanvullende data verzameld aan de hand van publieke APIs (Application Programming Interfaces). Hierbij worden platformen zoals Tripadvisor, Yelp en Google services(zoals Google maps) gebruikt om  openingsuren, gebruikersrecensies en statusvermeldingen (zoals “permanent gesloten”) automatisch op te halen. Hiervoor zullen LLM of scraping tools gebruikt worden. In dit onderzoek wordt voornamelijk gefocust op supermarkten  als POI type, aangezien deze regelmatig voorkomen in publieke datasets en bronnen. Bovendien is er voor deze soort POI vaak voldoende gebruikersactiviteit en data beschikbaar, wat de betrouwbaarheid van de data ten goede komt. De verzamelde data wordt opgeschoond en gefilterd, zodat deze gebruikt kunnen worden voor het trainen van het model. Het resultaat van deze fase is een dataset die klaar is voor de modeltraining en validatie.

\subsection{Fase 4 – Proof-of-Concept bouwen (3 werkdagen)}
De vierde fase wordt toegewijd aan het bouwen van een proof-of-concept. Hierbij wordt een eerste versie van een model ontwikkeld dat automatisch de open- of gesloten toestand van POI's kan detecteren. Het model wordt getraind op basis van de dataset uit de vorige fase. Daarnaast wordt er geëxperimenteerd met AI-technieken zoals tijdreeksanalyse en anomalie detectie. De implementatie gebeurt in Python, waarbij we gebruik maken van machine learning libraries zoals Pandas, Scikit-learn, TensorFlow en eventueel PyTorch. Het getrainde model met de beste evaluatiecriteria wordt opgeslagen met behulp van Joblib. Het resultaat van deze fase is een werkende proof-of-concept die in staat is om de status van een POI op een bepaald moment te classificeren als “open” of “gesloten”.

\subsection{Fase 5 – Proof-of-Concept valideren (3 werkdagen)}
In de vijfde fase van het onderzoek worden de opgeslagen modellen geëvalueerd op basis van evaluatiemetrics zoals accuracy, recall en precisie. Mogelijke validatiemethoden zijn het vergelijken met gekende sluitingsdata of handmatige verificatie van POI status. Daarnaast wordt gekeken welke kenmerken het meeste impact hebben op het model. hiervoor wordt gebruik gemaakt van feature importance in Python. Wanneer de modellen geëvalueerd zijn, volgt de vergelijkende studie. Hierin worden de modellen met elkaar vergeleken op basis van de bovenstaande criteria. Het resultaat van deze fase is een onderbouwde evaluatie van elk model en een grondige vergelijking op basis van de bekomen resultaten.

\subsection{Fase 6 – Conclusie (2 werkdagen)}
De laatste fase wordt toegewijd aan het formuleren van de conclusie. De resultaten van het onderzoek uit de voorgaande fasen worden gebundeld om aan te tonen
in welke mate artificiële intelligentie kan worden ingezet voor de automatische detectie van (historische) open of gesloten statussen van Point-of-interests. Daarnaast worden de bevindingen over de getrainde modellen toegelicht, met onder andere hun sterktes en zwaktes. Het resultaat van deze fase is een volledig uitgewerkte conclusie, aangevuld met eventuele suggesties voor verder onderzoek. 

 \begin{figure}[p]
    \centering
    \includegraphics[width=\textwidth]{Gantt_grafiek.png}
    \caption{\label{fig:gantt}Gantt diagram met de verschillende fasen van het onderzoek.}
\end{figure}

%---------- Verwachte resultaten ----------------------------------------------
\section{Verwacht resultaat, conclusie}%
\label{sec:verwachte_resultaten}

%Hier beschrijf je welke resultaten je verwacht. Als je metingen en simulaties uitvoert, kan je hier al mock-ups maken van de grafieken samen met de verwachte conclusies. Benoem zeker al je assen en de onderdelen van de grafiek die je gaat gebruiken. Dit zorgt ervoor dat je concreet weet welk soort data je moet verzamelen en hoe je die moet meten.
%Wat heeft de doelgroep van je onderzoek aan het resultaat? Op welke manier zorgt jouw bachelorproef voor een meerwaarde?
%Hier beschrijf je wat je verwacht uit je onderzoek, met de motivatie waarom. Het is \textbf{niet} erg indien uit je onderzoek andere resultaten en conclusies vloeien dan dat je hier beschrijft: het is dan juist interessant om te onderzoeken waarom jouw hypothesen niet overeenkomen met de resultaten.

Het doel van deze bachelorproef is om een (werkend) prototype te ontwikkelen dat automatisch kan voorspellen of een Point-of-Interest (zoals een supermarkt) open of gesloten is. Dit gebeurt met behulp van artificiële intelligentie. Er worden minstens twee AI-technieken getest: een klassiek classificatiemodel (zoals random forest classifier) en tijdreeksanalyse. Indien de timing het toelaat, zal ook anomaliedetectie worden onderzocht.

De modellen worden vergeleken op basis van evaluatiemetrics zoals accuracy, recall en precision. De validatie gebeurt met bekende sluitingsdata en eventueel handmatige controles. Daarnaast wordt bekeken welke kenmerken het meest bijdragen aan de voorspelling met behulp van een feature importance staafdiagram.

\textbf{Verwachte prestaties:} Op basis van de literatuurstudie, wordt verwacht dat het klassieke classificatiemodel het beste resultaat zal opleveren. Deze modellen zijn robuust voor kleine datasets en vereisen minder trainingstijd. Tijdreeksanalyse zou beter kunnen presteren in specifieke scenario’s, zoals seizoensgebondenheid. Het nadeel hierbij is dat het veel POI data nodig heeft en meer datavoorbereiding en feature engineering vereist.

Voor organisaties zoals Accurat is dit onderzoek relevant, aangezien het helpt om POI-data op een automatische manier up-to-date te houden. Dit verhoogt de kwaliteit van locatiegebaseerde analyses, zoals het meten van de marktactiviteit of bezoekersgedrag. Het onderzoek levert niet alleen een (werkend) prototype op, maar ook inzichten in welke technieken het best presteren voor het automatische detecteren van POI statussen.
